"""
–ì–æ–ª–æ—Å–æ–≤–æ–π –¥–≤–∏–∂–æ–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥–æ—Ç–æ–≤—ã—Ö open-source —Ä–µ—à–µ–Ω–∏–π
"""
import os
import sys
import json
import time
import queue
import threading
import wave
import numpy as np
from pathlib import Path
from typing import Optional, Dict, Any, List, Callable
from dataclasses import dataclass
import warnings
warnings.filterwarnings("ignore")

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
try:
    import pyaudio
    import torch
    #import torchaudio
    import speech_recognition as sr
    import pyttsx3
    HAS_AUDIO_DEPS = True
except ImportError as e:
    print(f"‚ö†Ô∏è –ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –∞—É–¥–∏–æ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: {e}")
    print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install pyaudio torch torchaudio SpeechRecognition pyttsx3")
    HAS_AUDIO_DEPS = False

@dataclass
class VoiceConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –¥–≤–∏–∂–∫–∞"""
    # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏
    speech_recognizer: str = "vosk"  # vosk, whisper, google
    language: str = "ru"
    sample_rate: int = 16000
    chunk_size: int = 4000
    
    # –°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏
    tts_engine: str = "pyttsx3"  # pyttsx3, silero
    voice_gender: str = "female"  # male, female
    speech_rate: int = 180
    
    # VAD (Voice Activity Detection)
    use_vad: bool = True
    vad_threshold: float = 0.5
    silence_duration: float = 1.0
    
    # –ê–∫—Ç–∏–≤–∞—Ü–∏—è
    activation_mode: str = "keyword"  # keyword, hotkey, always
    activation_keyword: str = "–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç"
    hotkey: str = "ctrl+alt+a"
    
    # –ü—É—Ç–∏ –∫ –º–æ–¥–µ–ª—è–º
    model_path: str = "models/voice"
    cache_path: str = "cache/audio"

class NeuralVoiceEngine:
    """
    –ì–æ–ª–æ—Å–æ–≤–æ–π –¥–≤–∏–∂–æ–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥–æ—Ç–æ–≤—ã—Ö open-source —Ä–µ—à–µ–Ω–∏–π
    """
    
    def __init__(self, config: Optional[VoiceConfig] = None):
        if not HAS_AUDIO_DEPS:
            raise ImportError("–ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –∞—É–¥–∏–æ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏")
        
        self.config = config or VoiceConfig()
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        self._create_directories()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self._init_speech_recognizer()
        self._init_tts_engine()
        self._init_vad()
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ
        self.is_listening = False
        self.is_speaking = False
        self.last_speech_time = 0
        self.activation_detected = False
        
        # –û—á–µ—Ä–µ–¥–∏ –∏ –ø–æ—Ç–æ–∫–∏
        self.audio_queue = queue.Queue(maxsize=100)
        self.command_queue = queue.Queue()
        self.processing_thread = None
        
        # –ö–æ–ª–ª–±—ç–∫–∏
        self.on_command_callback = None
        self.on_activation_callback = None
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            "total_audio_chunks": 0,
            "speech_detected": 0,
            "commands_recognized": 0,
            "recognition_errors": 0,
            "total_listening_time": 0.0
        }
        self._init_audio_stream()
        print("üé§ –ì–æ–ª–æ—Å–æ–≤–æ–π –¥–≤–∏–∂–æ–∫ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def _create_directories(self):
        """–°–æ–∑–¥–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
        directories = [
            self.config.model_path,
            self.config.cache_path,
            "logs/audio"
        ]
        
        for directory in directories:
            Path(directory).mkdir(parents=True, exist_ok=True)
    
    def _init_audio_stream(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ –ø–æ—Ç–æ–∫"""
        try:
            self.audio = pyaudio.PyAudio()
            
            # –ù–∞—Ö–æ–¥–∏–º –º–∏–∫—Ä–æ—Ñ–æ–Ω
            self.input_device_index = self._find_microphone()
            
            if self.input_device_index is None:
                print("‚ö†Ô∏è –ú–∏–∫—Ä–æ—Ñ–æ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É—é —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
                self.input_device_index = self.audio.get_default_input_device_info()["index"]
            
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ—Ç–æ–∫–∞
            self.stream = self.audio.open(
                format=pyaudio.paInt16,
                channels=1,
                rate=self.config.sample_rate,
                input=True,
                input_device_index=self.input_device_index,
                frames_per_buffer=self.config.chunk_size,
                stream_callback=self._audio_callback
            )
            
            print(f"üé§ –ê—É–¥–∏–æ –ø–æ—Ç–æ–∫ —Å–æ–∑–¥–∞–Ω: {self.config.sample_rate}Hz, chunk={self.config.chunk_size}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∞—É–¥–∏–æ –ø–æ—Ç–æ–∫–∞: {e}")
            self.audio = None
            self.stream = None
    
    def _find_microphone(self) -> Optional[int]:
        """–ù–∞—Ö–æ–¥–∏—Ç –º–∏–∫—Ä–æ—Ñ–æ–Ω –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é"""
        try:
            device_count = self.audio.get_device_count()
            
            for i in range(device_count):
                device_info = self.audio.get_device_info_by_index(i)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –∏–º–µ–µ—Ç –≤—Ö–æ–¥
                if device_info["maxInputChannels"] > 0:
                    device_name = device_info["name"].lower()
                    
                    # –ò—â–µ–º –º–∏–∫—Ä–æ—Ñ–æ–Ω –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏
                    keywords = ["microphone", "mic", "–º–∏–∫—Ä–æ—Ñ–æ–Ω", "–≤—Ö–æ–¥"]
                    if any(keyword in device_name for keyword in keywords):
                        print(f"‚úÖ –ù–∞–π–¥–µ–Ω –º–∏–∫—Ä–æ—Ñ–æ–Ω: {device_info['name']}")
                        return i
            
            return None
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞: {e}")
            return None
    
    def _audio_callback(self, in_data, frame_count, time_info, status):
        """Callback –¥–ª—è –∞—É–¥–∏–æ –ø–æ—Ç–æ–∫–∞"""
        try:
            if hasattr(self, 'is_listening') and self.is_listening:
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy –º–∞—Å—Å–∏–≤
                audio_data = np.frombuffer(in_data, dtype=np.int16)
            
                # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ—á–µ—Ä–µ–¥—å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
                try:
                    self.audio_queue.put_nowait({
                        'data': audio_data,
                        'timestamp': time.time()
                    })
                    self.stats["total_audio_chunks"] += 1
                except queue.Full:
                    pass
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ audio callback: {e}")
    
        return (in_data, pyaudio.paContinue)
    
    def _init_speech_recognizer(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—å —Ä–µ—á–∏"""
        print(f"üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—è —Ä–µ—á–∏: {self.config.speech_recognizer}")
        
        if self.config.speech_recognizer == "vosk":
            self._init_vosk_recognizer()
        elif self.config.speech_recognizer == "whisper":
            self._init_whisper_recognizer()
        elif self.config.speech_recognizer == "google":
            self._init_google_recognizer()
        else:
            print(f"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—å: {self.config.speech_recognizer}")
            print("üîÑ –ò—Å–ø–æ–ª—å–∑—É—é Google Speech Recognition")
            self._init_google_recognizer()
    
    def _init_vosk_recognizer(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç Vosk —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—å (–æ—Ñ—Ñ–ª–∞–π–Ω)"""
        try:
            import vosk
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
            model_path = Path(self.config.model_path) / "vosk-model-small-ru"
            
            if not model_path.exists():
                print("üì• –°–∫–∞—á–∏–≤–∞—é –º–æ–¥–µ–ª—å Vosk –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞...")
                self._download_vosk_model()
            
            if model_path.exists():
                self.vosk_model = vosk.Model(str(model_path))
                self.vosk_recognizer = vosk.KaldiRecognizer(
                    self.vosk_model, 
                    self.config.sample_rate
                )
                print("‚úÖ Vosk —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            else:
                print("‚ö†Ô∏è –ú–æ–¥–µ–ª—å Vosk –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É—é Google")
                self._init_google_recognizer()
                
        except ImportError:
            print("‚ö†Ô∏è Vosk –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É—é Google")
            print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install vosk")
            self._init_google_recognizer()
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Vosk: {e}")
            self._init_google_recognizer()
    
    def _download_vosk_model(self):
        """–°–∫–∞—á–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª—å Vosk"""
        try:
            import urllib.request
            import zipfile
            
            model_url = "https://alphacephei.com/vosk/models/vosk-model-small-ru-0.22.zip"
            zip_path = Path(self.config.model_path) / "vosk-model-small-ru.zip"
            
            print(f"üì• –°–∫–∞—á–∏–≤–∞—é –º–æ–¥–µ–ª—å —Å {model_url}")
            
            # –°–∫–∞—á–∏–≤–∞–µ–º
            urllib.request.urlretrieve(model_url, zip_path)
            
            # –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(self.config.model_path)
            
            # –£–¥–∞–ª—è–µ–º –∞—Ä—Ö–∏–≤
            zip_path.unlink()
            
            print("‚úÖ –ú–æ–¥–µ–ª—å Vosk –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ Vosk: {e}")
    
    def _init_whisper_recognizer(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç Whisper —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—å"""
        try:
            import whisper
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–∏
            model_size = "small"  # tiny, base, small, medium, large
            
            print(f"üîÑ –ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å Whisper ({model_size})...")
            self.whisper_model = whisper.load_model(model_size)
            
            print("‚úÖ Whisper —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            
        except ImportError:
            print("‚ö†Ô∏è Whisper –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É—é Google")
            print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install openai-whisper")
            self._init_google_recognizer()
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Whisper: {e}")
            self._init_google_recognizer()
    
    def _init_google_recognizer(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç Google Speech Recognition"""
        try:
            self.google_recognizer = sr.Recognizer()
        
            # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω
            try:
                self.google_microphone = sr.Microphone()
            
                # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –¥–ª—è —à—É–º–Ω–æ–π —Å—Ä–µ–¥—ã
                with self.google_microphone as source:
                    self.google_recognizer.adjust_for_ambient_noise(source, duration=1)
            
                print("‚úÖ Google Speech Recognition –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            
            except Exception as mic_error:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–∏–∫—Ä–æ—Ñ–æ–Ω: {mic_error}")
                self.google_microphone = None
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Google Speech Recognition: {e}")
            print("‚ö†Ô∏è –ì–æ–ª–æ—Å–æ–≤–æ–π –≤–≤–æ–¥ –±—É–¥–µ—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            self.google_recognizer = None
            self.google_microphone = None
    
    def _init_tts_engine(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–∏–Ω—Ç–µ–∑–∞—Ç–æ—Ä —Ä–µ—á–∏"""
        print(f"üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è TTS: {self.config.tts_engine}")
        
        if self.config.tts_engine == "pyttsx3":
            self._init_pyttsx3()
        elif self.config.tts_engine == "silero":
            self._init_silero()
        else:
            print(f"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π TTS: {self.config.tts_engine}")
            print("üîÑ –ò—Å–ø–æ–ª—å–∑—É—é pyttsx3")
            self._init_pyttsx3()
    
    def _init_pyttsx3(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç pyttsx3 TTS"""
        try:
            self.tts_engine = pyttsx3.init()
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–æ–ª–æ—Å–∞
            self.tts_engine.setProperty('rate', self.config.speech_rate)
            
            # –í—ã–±–∏—Ä–∞–µ–º –≥–æ–ª–æ—Å
            voices = self.tts_engine.getProperty('voices')
            
            if self.config.voice_gender == "female" and len(voices) > 1:
                # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∂–µ–Ω—Å–∫–∏–π –≥–æ–ª–æ—Å
                for voice in voices:
                    if "female" in voice.name.lower() or "–∂–µ–Ω—Å–∫" in voice.name.lower():
                        self.tts_engine.setProperty('voice', voice.id)
                        break
                else:
                    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Ç–æ—Ä–æ–π –≥–æ–ª–æ—Å
                    self.tts_engine.setProperty('voice', voices[1].id)
            else:
                # –ú—É–∂—Å–∫–æ–π –≥–æ–ª–æ—Å
                self.tts_engine.setProperty('voice', voices[0].id)
            
            print(f"‚úÖ pyttsx3 TTS –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ pyttsx3: {e}")
            self.tts_engine = None
    
    def _init_silero(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç Silero TTS (–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –æ—Ñ—Ñ–ª–∞–π–Ω)"""
        try:
            import torch
            language = 'ru'
            model_id = 'v3_1_ru'
            device = torch.device('cpu')
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
            torch.hub.download_url_to_file(
                f'https://models.silero.ai/models/tts/{language}/{model_id}.pt',
                f'{self.config.model_path}/silero_{model_id}.pt'
            )
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º
            self.silero_model = torch.package.PackageImporter(
                f'{self.config.model_path}/silero_{model_id}.pt'
            ).load_pickle("tts_models", "model")
            
            self.silero_model.to(device)
            
            # –í—ã–±–∏—Ä–∞–µ–º –≥–æ–ª–æ—Å
            self.silero_speaker = 'baya'  # baya, kseniya, aidar, eugene, random
            
            print("‚úÖ Silero TTS –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Silero: {e}")
            print("üîÑ –ò—Å–ø–æ–ª—å–∑—É—é pyttsx3")
            self._init_pyttsx3()
    
    def _init_vad(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç Voice Activity Detection"""
        if self.config.use_vad:
            try:
                import webrtcvad
                self.vad = webrtcvad.Vad(2)  # 0-3, –≥–¥–µ 3 —Å–∞–º—ã–π –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π
                print("‚úÖ VAD –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            except ImportError:
                print("‚ö†Ô∏è webrtcvad –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, VAD –æ—Ç–∫–ª—é—á–µ–Ω")
                print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install webrtcvad")
                self.config.use_vad = False
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ VAD: {e}")
                self.config.use_vad = False
    
    def start_listening(self):
        """–ù–∞—á–∏–Ω–∞–µ—Ç –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏–µ"""
        if not self.is_listening:
            print("üëÇ –ù–∞—á–∏–Ω–∞—é –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏–µ...")
            self.is_listening = True
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            self.processing_thread = threading.Thread(
                target=self._processing_loop,
                daemon=True
            )
            self.processing_thread.start()
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
            if self.config.activation_mode == "keyword":
                self.activation_thread = threading.Thread(
                    target=self._activation_detection_loop,
                    daemon=True
                )
                self.activation_thread.start()
    
    def stop_listening(self):
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏–µ"""
        if self.is_listening:
            print("üõë –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏–µ...")
            self.is_listening = False
            
            if self.processing_thread:
                self.processing_thread.join(timeout=2)
            
            # –û—á–∏—â–∞–µ–º –æ—á–µ—Ä–µ–¥–∏
            while not self.audio_queue.empty():
                try:
                    self.audio_queue.get_nowait()
                except queue.Empty:
                    break
    
    def _processing_loop(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ"""
        audio_buffer = []
        buffer_duration = 0
        last_audio_time = time.time()
        
        while self.is_listening:
            try:
                # –ü–æ–ª—É—á–∞–µ–º –∞—É–¥–∏–æ —á–∞–Ω–∫
                chunk = self.audio_queue.get(timeout=0.1)
                audio_data = chunk['data']
                timestamp = chunk['timestamp']
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º VAD
                is_speech = self._detect_speech(audio_data)
                
                if is_speech:
                    self.stats["speech_detected"] += 1
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –≤ –±—É—Ñ–µ—Ä
                    audio_buffer.append(audio_data)
                    buffer_duration += len(audio_data) / self.config.sample_rate
                    last_audio_time = timestamp
                    
                    # –ï—Å–ª–∏ –Ω–∞–∫–æ–ø–∏–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∞—É–¥–∏–æ, —Ä–∞—Å–ø–æ–∑–Ω–∞–µ–º
                    if buffer_duration >= 1.0:  # 1 —Å–µ–∫—É–Ω–¥–∞
                        self._process_audio_buffer(audio_buffer)
                        audio_buffer = []
                        buffer_duration = 0
                
                else:
                    # –ï—Å–ª–∏ –±—ã–ª–∞ —Ä–µ—á—å –∏ —Ç–µ–ø–µ—Ä—å —Ç–∏—à–∏–Ω–∞
                    if audio_buffer and (timestamp - last_audio_time) > self.config.silence_duration:
                        self._process_audio_buffer(audio_buffer)
                        audio_buffer = []
                        buffer_duration = 0
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤—Ä–µ–º–µ–Ω–∏
                self.stats["total_listening_time"] += 0.1
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –≤ processing loop: {e}")
                self.stats["recognition_errors"] += 1
    
    def _detect_speech(self, audio_data: np.ndarray) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –µ—Å—Ç—å –ª–∏ —Ä–µ—á—å –≤ –∞—É–¥–∏–æ"""
        if not self.config.use_vad:
            return True  # –ï—Å–ª–∏ VAD –æ—Ç–∫–ª—é—á–µ–Ω, —Å—á–∏—Ç–∞–µ–º —á—Ç–æ –≤—Å–µ–≥–¥–∞ –µ—Å—Ç—å —Ä–µ—á—å
        
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è VAD
            audio_int16 = audio_data.astype(np.int16)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π —Ñ—Ä–µ–π–º (30ms)
            frame_duration = 30  # ms
            frame_size = int(self.config.sample_rate * frame_duration / 1000)
            
            is_speech_frames = 0
            total_frames = 0
            
            for i in range(0, len(audio_int16), frame_size):
                frame = audio_int16[i:i+frame_size]
                if len(frame) < frame_size:
                    continue
                
                try:
                    if self.vad.is_speech(frame.tobytes(), self.config.sample_rate):
                        is_speech_frames += 1
                    total_frames += 1
                except:
                    pass
            
            if total_frames > 0:
                speech_ratio = is_speech_frames / total_frames
                return speech_ratio > self.config.vad_threshold
            
            return False
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ VAD: {e}")
            return True  # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ —Å—á–∏—Ç–∞–µ–º —á—Ç–æ –µ—Å—Ç—å —Ä–µ—á—å
    
    def _process_audio_buffer(self, audio_buffer: List[np.ndarray]):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π –∞—É–¥–∏–æ –±—É—Ñ–µ—Ä"""
        if not audio_buffer:
            return
        
        try:
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —á–∞–Ω–∫–∏
            combined_audio = np.concatenate(audio_buffer)
            
            # –†–∞—Å–ø–æ–∑–Ω–∞–µ–º —Ä–µ—á—å
            text = self._recognize_speech(combined_audio)
            
            if text and text.strip():
                print(f"üé§ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {text}")
                self.stats["commands_recognized"] += 1
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–∫—Ç–∏–≤–∞—Ü–∏—é
                if self._check_activation(text):
                    self.activation_detected = True
                    if self.on_activation_callback:
                        self.on_activation_callback(text)
                
                # –ï—Å–ª–∏ –≤—Å–µ–≥–¥–∞ —Å–ª—É—à–∞–µ–º –∏–ª–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞
                if self.config.activation_mode == "always" or self.activation_detected:
                    if self.on_command_callback:
                        self.on_command_callback(text)
                    
                    # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∞–∫—Ç–∏–≤–∞—Ü–∏—é –ø–æ—Å–ª–µ –∫–æ–º–∞–Ω–¥—ã
                    if self.config.activation_mode == "keyword":
                        self.activation_detected = False
        
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ: {e}")
            self.stats["recognition_errors"] += 1
    
    def _recognize_speech(self, audio_data: np.ndarray) -> Optional[str]:
        """–†–∞—Å–ø–æ–∑–Ω–∞–µ—Ç —Ä–µ—á—å –∏–∑ –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            if self.config.speech_recognizer == "vosk":
                return self._recognize_vosk(audio_data)
            elif self.config.speech_recognizer == "whisper":
                return self._recognize_whisper(audio_data)
            elif self.config.speech_recognizer == "google":
                return self._recognize_google(audio_data)
            else:
                return self._recognize_google(audio_data)
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏: {e}")
            return None
    
    def _recognize_vosk(self, audio_data: np.ndarray) -> Optional[str]:
        """–†–∞—Å–ø–æ–∑–Ω–∞–µ—Ç —Å –ø–æ–º–æ—â—å—é Vosk"""
        if not hasattr(self, 'vosk_recognizer'):
            return None
        
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –±–∞–π—Ç—ã
            audio_bytes = audio_data.astype(np.int16).tobytes()
            
            # –†–∞—Å–ø–æ–∑–Ω–∞–µ–º
            if self.vosk_recognizer.AcceptWaveform(audio_bytes):
                result = json.loads(self.vosk_recognizer.Result())
                return result.get("text", "")
            else:
                result = json.loads(self.vosk_recognizer.PartialResult())
                return result.get("partial", "")
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ Vosk —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {e}")
            return None
    
    def _recognize_whisper(self, audio_data: np.ndarray) -> Optional[str]:
        """–†–∞—Å–ø–æ–∑–Ω–∞–µ—Ç —Å –ø–æ–º–æ—â—å—é Whisper"""
        if not hasattr(self, 'whisper_model'):
            return None
        
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ float32
            audio_float = audio_data.astype(np.float32) / 32768.0
            
            # –†–∞—Å–ø–æ–∑–Ω–∞–µ–º
            result = self.whisper_model.transcribe(
                audio_float,
                language=self.config.language,
                fp16=False  # –ò—Å–ø–æ–ª—å–∑—É–µ–º float32 –¥–ª—è CPU
            )
            
            return result.get("text", "")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ Whisper —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {e}")
            return None
    
    def _recognize_google(self, audio_data: np.ndarray) -> Optional[str]:
        """–†–∞—Å–ø–æ–∑–Ω–∞–µ—Ç —Å –ø–æ–º–æ—â—å—é Google Speech Recognition"""
        if not hasattr(self, 'google_recognizer'):
            return None
        
        try:
            # –°–æ–∑–¥–∞–µ–º AudioData –æ–±—ä–µ–∫—Ç
            audio_sr = sr.AudioData(
                audio_data.tobytes(),
                self.config.sample_rate,
                2  # sample width in bytes
            )
            
            # –†–∞—Å–ø–æ–∑–Ω–∞–µ–º
            text = self.google_recognizer.recognize_google(
                audio_sr,
                language=f"{self.config.language}-{self.config.language.upper()}"
            )
            
            return text
            
        except sr.UnknownValueError:
            # –†–µ—á—å –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞
            return None
        except sr.RequestError as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ Google Speech Recognition: {e}")
            return None
        except Exception as e:
            print(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
            return None
    
    def _activation_detection_loop(self):
        """–¶–∏–∫–ª –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞"""
        print("üîç –ó–∞–ø—É—Å–∫–∞—é –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞...")
        
        activation_buffer = []
        
        while self.is_listening and self.config.activation_mode == "keyword":
            try:
                # –ü–æ–ª—É—á–∞–µ–º –∞—É–¥–∏–æ —á–∞–Ω–∫
                chunk = self.audio_queue.get(timeout=0.5)
                audio_data = chunk['data']
                
                # –î–æ–±–∞–≤–ª—è–µ–º –≤ –±—É—Ñ–µ—Ä
                activation_buffer.append(audio_data)
                
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –±—É—Ñ–µ—Ä–∞ (3 —Å–µ–∫—É–Ω–¥—ã)
                if len(activation_buffer) > 3 * self.config.sample_rate / self.config.chunk_size:
                    activation_buffer.pop(0)
                
                # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –±—É—Ñ–µ—Ä
                if len(activation_buffer) >= 5:  # –ü—Ä–∏–º–µ—Ä–Ω–æ 0.5 —Å–µ–∫—É–Ω–¥—ã
                    combined = np.concatenate(activation_buffer)
                    text = self._recognize_speech(combined)
                    
                    if text and self._check_activation(text):
                        print(f"‚úÖ –ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ: {text}")
                        self.activation_detected = True
                        activation_buffer = []  # –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä
                    
                    # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–π –±—É—Ñ–µ—Ä
                    activation_buffer = activation_buffer[-5:]
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –∞–∫—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω–æ–º —Ü–∏–∫–ª–µ: {e}")
    
    def _check_activation(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Ç–µ–∫—Å—Ç –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ"""
        if not text:
            return False
        
        text_lower = text.lower()
        keyword = self.config.activation_keyword.lower()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º—ã –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞
        variations = [
            keyword,
            keyword + " ",
            " " + keyword,
            keyword + ",",
            keyword + "."
        ]
        
        for variation in variations:
            if variation in text_lower:
                return True
        
        return False
    
    def speak(self, text: str, wait: bool = True):
        """
        –û–∑–≤—É—á–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∏–≤–∞–Ω–∏—è
            wait: –ñ–¥–∞—Ç—å –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
        """
        if not text or self.is_speaking:
            return
        
        print(f"üó£Ô∏è –û–∑–≤—É—á–∏–≤–∞—é: {text[:50]}...")
        self.is_speaking = True
        
        try:
            if self.config.tts_engine == "silero" and hasattr(self, 'silero_model'):
                self._speak_silero(text, wait)
            elif hasattr(self, 'tts_engine') and self.tts_engine:
                self._speak_pyttsx3(text, wait)
            else:
                print(f"‚ö†Ô∏è TTS –¥–≤–∏–∂–æ–∫ –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")
        
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏: {e}")
        
        finally:
            self.is_speaking = False
    
    def _speak_pyttsx3(self, text: str, wait: bool):
        """–û–∑–≤—É—á–∏–≤–∞–µ—Ç —Å –ø–æ–º–æ—â—å—é pyttsx3"""
        self.tts_engine.say(text)
        
        if wait:
            self.tts_engine.runAndWait()
        else:
            # –ó–∞–ø—É—Å–∫–∞–µ–º –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
            def speak_thread():
                self.tts_engine.runAndWait()
            
            threading.Thread(target=speak_thread, daemon=True).start()
    
    def _speak_silero(self, text: str, wait: bool):
        """–û–∑–≤—É—á–∏–≤–∞–µ—Ç —Å –ø–æ–º–æ—â—å—é Silero"""
        try:
            import torchaudio
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ—á—å
            audio = self.silero_model.apply_tts(
                text=text,
                speaker=self.silero_speaker,
                sample_rate=24000
            )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            temp_file = Path(self.config.cache_path) / f"tts_{int(time.time())}.wav"
            torchaudio.save(str(temp_file), audio.unsqueeze(0), 24000)
            
            # –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º
            self._play_audio_file(temp_file)
            
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            if wait:
                while self.is_playing_audio:
                    time.sleep(0.1)
                temp_file.unlink()
            else:
                threading.Thread(
                    target=self._wait_and_delete,
                    args=(temp_file,),
                    daemon=True
                ).start()
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ Silero TTS: {e}")
            # Fallback –Ω–∞ pyttsx3
            if hasattr(self, 'tts_engine'):
                self._speak_pyttsx3(text, wait)
    
    def _play_audio_file(self, filepath: Path):
        """–í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç –∞—É–¥–∏–æ —Ñ–∞–π–ª"""
        try:
            import pyaudio
            import wave
            
            wf = wave.open(str(filepath), 'rb')
            
            p = pyaudio.PyAudio()
            stream = p.open(
                format=p.get_format_from_width(wf.getsampwidth()),
                channels=wf.getnchannels(),
                rate=wf.getframerate(),
                output=True
            )
            
            data = wf.readframes(1024)
            while data:
                stream.write(data)
                data = wf.readframes(1024)
            
            stream.stop_stream()
            stream.close()
            p.terminate()
            wf.close()
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –∞—É–¥–∏–æ: {e}")
    
    def _wait_and_delete(self, filepath: Path):
        """–ñ–¥–µ—Ç –∏ —É–¥–∞–ª—è–µ—Ç —Ñ–∞–π–ª"""
        time.sleep(5)  # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
        if filepath.exists():
            filepath.unlink()
    
    def listen_once(self, timeout: float = 5.0) -> Optional[str]:
        """
        –°–ª—É—à–∞–µ—Ç –æ–¥–Ω—É –∫–æ–º–∞–Ω–¥—É —Å —Ç–∞–π–º–∞—É—Ç–æ–º
        """
        print(f"üëÇ –°–ª—É—à–∞—é –∫–æ–º–∞–Ω–¥—É (—Ç–∞–π–º–∞—É—Ç: {timeout}—Å)...")
    
        if not hasattr(self, 'google_recognizer') or not self.google_recognizer:
            print("‚ùå –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            return None
    
        if not hasattr(self, 'google_microphone') or not self.google_microphone:
            print("‚ùå –ú–∏–∫—Ä–æ—Ñ–æ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return None
    
        try:
            with self.google_microphone as source:
                self.google_recognizer.adjust_for_ambient_noise(source, duration=0.5)
                print("üé§ –ì–æ–≤–æ—Ä–∏—Ç–µ —Å–µ–π—á–∞—Å...")
                audio = self.google_recognizer.listen(source, timeout=timeout, phrase_time_limit=3)
            
                text = self.google_recognizer.recognize_google(
                    audio,
                    language=f"{self.config.language}-{self.config.language.upper()}"
                )
            
                print(f"‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {text}")
                return text
            
        except sr.WaitTimeoutError:
            print("‚è∞ –¢–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã")
            return None
        except sr.UnknownValueError:
            print("ü§∑ –†–µ—á—å –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞")
            return None
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è: {e}")
            return None
    
    def set_command_callback(self, callback: Callable[[str], None]):
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∫–æ–ª–ª–±—ç–∫ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã—Ö –∫–æ–º–∞–Ω–¥"""
        self.on_command_callback = callback
    
    def set_activation_callback(self, callback: Callable[[str], None]):
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∫–æ–ª–ª–±—ç–∫ –¥–ª—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏"""
        self.on_activation_callback = callback
    
    def get_stats(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        return self.stats.copy()
    
    def save_audio_debug(self, audio_data: np.ndarray, filename: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∞—É–¥–∏–æ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏"""
        try:
            import soundfile as sf
            
            debug_dir = Path("logs/audio")
            debug_dir.mkdir(exist_ok=True)
            
            filepath = debug_dir / f"{filename}_{int(time.time())}.wav"
            sf.write(str(filepath), audio_data, self.config.sample_rate)
            
            print(f"üíæ –ê—É–¥–∏–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {filepath}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞—É–¥–∏–æ: {e}")
    
    def cleanup(self):
        """–û—á–∏—â–∞–µ—Ç —Ä–µ—Å—É—Ä—Å—ã"""
        print("üßπ –û—á–∏—Å—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –¥–≤–∏–∂–∫–∞...")
        
        self.stop_listening()
        
        if hasattr(self, 'stream') and self.stream:
            self.stream.stop_stream()
            self.stream.close()
        
        if hasattr(self, 'audio') and self.audio:
            self.audio.terminate()

# –£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
def test_voice_engine():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –≥–æ–ª–æ—Å–æ–≤–æ–π –¥–≤–∏–∂–æ–∫"""
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –¥–≤–∏–∂–∫–∞...")
    
    if not HAS_AUDIO_DEPS:
        print("‚ùå –ê—É–¥–∏–æ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")
        return
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    config = VoiceConfig(
        speech_recognizer="google",  # –ù–∞—á–Ω–µ–º —Å Google –¥–ª—è —Ç–µ—Å—Ç–∞
        activation_mode="always",    # –í—Å–µ–≥–¥–∞ —Å–ª—É—à–∞–µ–º –¥–ª—è —Ç–µ—Å—Ç–∞
        use_vad=False                # –û—Ç–∫–ª—é—á–∞–µ–º VAD –¥–ª—è —Ç–µ—Å—Ç–∞
    )
    
    try:
        engine = NeuralVoiceEngine(config)
        
        print("\nüîä –¢–µ—Å—Ç —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏...")
        engine.speak("–ü—Ä–∏–≤–µ—Ç! –Ø –≥–æ–ª–æ—Å–æ–≤–æ–π –¥–≤–∏–∂–æ–∫. –ì–æ—Ç–æ–≤ –∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—é.")
        time.sleep(2)
        
        print("\nüëÇ –¢–µ—Å—Ç –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è –æ–¥–Ω–æ–π –∫–æ–º–∞–Ω–¥—ã...")
        print("–°–∫–∞–∂–∏—Ç–µ —á—Ç–æ-–Ω–∏–±—É–¥—å –≤ —Ç–µ—á–µ–Ω–∏–µ 5 —Å–µ–∫—É–Ω–¥...")
        
        text = engine.listen_once(timeout=5)
        
        if text:
            print(f"‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {text}")
            engine.speak(f"–í—ã —Å–∫–∞–∑–∞–ª–∏: {text}")
        else:
            print("‚ùå –ù–∏—á–µ–≥–æ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ")
            engine.speak("–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —è –Ω–∏—á–µ–≥–æ –Ω–µ —Ä–∞—Å—Å–ª—ã—à–∞–ª–∞")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = engine.get_stats()
        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {stats}")
        
        # –û—á–∏—Å—Ç–∫–∞
        engine.cleanup()
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        import traceback
        traceback.print_exc()

# –ü—Ä–æ—Å—Ç–æ–π –ø—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
class SimpleVoiceAssistant:
    """–ü—Ä–æ—Å—Ç–æ–π –≥–æ–ª–æ—Å–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
    
    def __init__(self):
        self.config = VoiceConfig(
            speech_recognizer="google",
            activation_mode="keyword",
            activation_keyword="–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç"
        )
        
        self.engine = NeuralVoiceEngine(self.config)
        self.engine.set_command_callback(self.on_command)
        self.engine.set_activation_callback(self.on_activation)
        
        self.is_running = False
    
    def on_command(self, text: str):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥—ã"""
        print(f"üéØ –ö–æ–º–∞–Ω–¥–∞: {text}")
        
        # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ –æ—Ç–≤–µ—Ç–∞
        if "–ø—Ä–∏–≤–µ—Ç" in text.lower():
            self.engine.speak("–ü—Ä–∏–≤–µ—Ç! –†–∞–¥–∞ –≤–∞—Å —Å–ª—ã—à–∞—Ç—å!")
        elif "–∫–∞–∫ –¥–µ–ª–∞" in text.lower():
            self.engine.speak("–í—Å—ë –æ—Ç–ª–∏—á–Ω–æ! –ì–æ—Ç–æ–≤–∞ –ø–æ–º–æ–≥–∞—Ç—å!")
        elif "–ø–æ–∫–∞" in text.lower() or "–¥–æ —Å–≤–∏–¥–∞–Ω–∏—è" in text.lower():
            self.engine.speak("–î–æ —Å–≤–∏–¥–∞–Ω–∏—è! –ë—ã–ª–∞ —Ä–∞–¥–∞ –ø–æ–º–æ—á—å!")
            self.stop()
        else:
            self.engine.speak(f"–í—ã —Å–∫–∞–∑–∞–ª–∏: {text}")
    
    def on_activation(self, text: str):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏"""
        print(f"üîî –ê–∫—Ç–∏–≤–∞—Ü–∏—è –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É: {text}")
        self.engine.speak("–î–∞, —è —Å–ª—É—à–∞—é!")
    
    def start(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞"""
        print("üöÄ –ó–∞–ø—É—Å–∫ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞...")
        print(f"üí° –°–∫–∞–∂–∏—Ç–µ '{self.config.activation_keyword}' –¥–ª—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏")
        
        self.is_running = True
        self.engine.start_listening()
        
        # –ì–ª–∞–≤–Ω—ã–π —Ü–∏–∫–ª
        try:
            while self.is_running:
                time.sleep(1)
        except KeyboardInterrupt:
            print("\nüõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ Ctrl+C")
        finally:
            self.stop()
    
    def stop(self):
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞"""
        if self.is_running:
            print("üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞...")
            self.is_running = False
            self.engine.cleanup()

if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º
    test_voice_engine()
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ—Å—Ç–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
    # assistant = SimpleVoiceAssistant()
    # assistant.start()